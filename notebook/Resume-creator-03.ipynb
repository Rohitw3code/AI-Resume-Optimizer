{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78db232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e34062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent,Task,Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4574464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "serper_api_key = os.getenv(\"SERPER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d1db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = openai_api_key\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
    "os.environ[\"SERPER_API_KEY\"] = serper_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6b6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_text = '''\n",
    "social link : - rohitcode005@gmail.com- github.com/Rohitw3code\n",
    " collage : Sarala Birla University\n",
    " Degree : B.Tech in AI (Artificial Intelligence)\n",
    " Ranchi ,Jharkhand\n",
    " graduation year : 11/2021- 04/2025\n",
    "'''\n",
    "\n",
    "skills_text = '''\n",
    " Programming Languages: Python, C++,C,Java,Javascript,C sharp\n",
    " Libraries and Tools: Tensorflow,HuggingFace,Langchain, PyTorch, Sklearn, Pandas, Numpy, OpenCV, LLM, flask,\n",
    " react, NLP, nodejs, android app, sql, etl, IOT, eps32, arduino, Git, firebase, mongodb, Linux, Neural network, cude,\n",
    " no sql, Docker\n",
    " ML Architectures: CNN, YOLO, Transformers(BERT, LSTM)\n",
    "'''\n",
    "\n",
    "experience_text = '''\n",
    " WORK EXPERIENCE\n",
    " Data Engineer\n",
    " Taiyo.ai, San Francisco california, USA\n",
    " • Conduct web scraping to extract data from both the World Bank and IADB etc websites\n",
    " remote-internship\n",
    " 06/2022- 09/2022\n",
    " • Python scripting in oops (object oriented programming) and establishment of a robust data pipeline for seamless\n",
    " integration with Google Cloud.\n",
    " • Data Preprocessing,data analysis using Pandas and NumPy, matplotplib,seaborn.\n",
    " Prompt Engineer\n",
    " Scale AI, remote\n",
    " 09/2023- 02/2024\n",
    " • Review LLM model code generation Data science and ML training expert improved prompt generative AI model for\n",
    " better performance.\n",
    "'''\n",
    "\n",
    "project_text = '''\n",
    " PROJECTS\n",
    " • AI ResumeRover (LLM langchain) (09/2023) Functionality: A platform for HR to upload and manage hundreds\n",
    " of resumes simultaneously. Enabled HR to filter resumes efficiently based on project needs and employee.\n",
    " Technology Stack: Langchain and fine-tuned with OpenAI and FAISS , Python , Streamlit Video show case GitHub\n",
    " • Data Science QuickFlow (11/2023) Developed a web tool for a data scientist using Flask,React,Tailwind\n",
    " CSS,Pandas,and NumPy.This platform enables data scientists to perform all data preprocessing task,feature\n",
    " selection, and machine learning model training tasks without writing code. It supports 17 regression and 20\n",
    " classification algorithms and code generationVideo show case Github\n",
    " • MedDiag: AI-Powered Disease Diagnosis and Doctor Report Summary (02/2024) Developed a web app that\n",
    " predicts disease types from images using deep learning with CNN. It supports three types of images: bone\n",
    " fractures, skin diseases, and CT scans of brain tumors. The site classifies the disease, displays symptoms, describes\n",
    " the condition, and suggests precautions.it also summarize doctor report cards for easier understanding.\n",
    " • (Reinforcement Learning) AI Maze Solver: Q-Learning Project (03/2024) Created a maze game where an AI\n",
    " agent navigates towards the goal using the Q-Learning Algorithm.Developed entirely from scratch in Python\n",
    " pygame video show case Github\n",
    " • Speech Emotion Detection (08/2023) Created a website capable of analyzing user speech to predict their\n",
    " emotional state. The system can classify emotions such as anger, surprise, happiness, sadness, disgust, crying, and\n",
    " normal emotion Check out!\n",
    " • Object Detection from Scratch YOLO (01/2024) Build end-to-end Pileline to preprocess data and Train and test\n",
    " the model and Realtime Object Detection Tensorflow,numpy,matplotlib,opencv Check out!\n",
    " • Codeddit App Developed a community app for developers (8k+ download) Codeddit App-Playstor\n",
    " \n",
    " \n",
    "  whatsapp chat classifier\n",
    " Apr 2023 - Apr 2023\n",
    " https://github.com/Rohitw3code/Whatsapp-chat\n",
    "classification-NLP\n",
    " I have developed a chat classification model that can\n",
    " accurately identify the author of a message based on\n",
    " user input. Specifically, I utilized exported WhatsApp chat\n",
    "data and applied natural language processing techniques\n",
    " to train the model\n",
    " \n",
    " Air Draw whiteboard-hand-gesture computer vision\n",
    " Jan 2023 - Jan 2023\n",
    " https://github.com/Rohitw3code/whiteboard-hand\n",
    "gesture\n",
    "Air Draw using two finger Hand Guesture , user can also\n",
    " drag the canvas using hand move\n",
    " Movie Recommendation\n",
    " Jan 2023 - Jan 2023\n",
    " https://github.com/Rohitw3code/Movie-Recommendation\n",
    " This movie recommendation project uses NLTK and\n",
    " sklearn to analyze user reviews and ratings, identifying\n",
    " movie characteristics to provide personalized\n",
    " recommendations.\n",
    " Image--classification-and-Localization-CIFAR10\n",
    " Dec 2022 - Dec 2022\n",
    " https://github.com/Rohitw3code/Image--classification\n",
    "and-Localization-CIFAR10\n",
    " Website that has two Tab the First tab is used to classify\n",
    " the CIFAR10 images\n",
    " and the secound Tab is used to Localize the images of\n",
    " cucumber , eggplant , mushroom\n",
    " ComputerVision-Lips -mask-and-eyepatch\n",
    "snapchat-filter\n",
    " Dec 2022 - Dec 2022\n",
    " https://github.com/Rohitw3code/ComputerVision-mask\n",
    "and-eyepatch-snapchat-filter\n",
    " This is AR Project which put the mask , eye patch on the\n",
    " person face , it also make the lips color (Realistic) ...this is\n",
    " inspired from the real world app SnapChat\n",
    " Air Draw\n",
    " May 2022 - May 2022\n",
    " https://github.com/Rohitw3code/Air-Draw-OpenCV\n",
    " OpenCV project to draw canvas in air using color\n",
    " detection technique\n",
    " Computer-vision-stone-paper-scissor\n",
    " Jan 2022 - Jan 2022\n",
    " https://github.com/Rohitw3code/Computer-vision-stone\n",
    "paper-scissor\n",
    "\n",
    " Stone Paper Scissor game , user hand gesture is detected\n",
    " how the hand is shown in front of camers\n",
    " Computer-vision-Emojis-Detector from the human\n",
    " face\n",
    " Jan 2022 - Jan 2022\n",
    "https://github.com/Rohitw3code/Computer-vision-Emojis\n",
    "Detector\n",
    " this project scan the user face and display the emoji\n",
    " accroding the face of the user \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "activity_text = '''\n",
    " EXTRACURRICULAR ACTIVITIES\n",
    " Samsung Solve for Tomorrow\n",
    " CSR FITT , Delhi\n",
    " 06/2023\n",
    " • Achieved a remarkable ranking in the Top 30 among more than 70,000 participants for developing an innovative\n",
    " mobile application that provide instantaneous solutions and support to a developer Laper App-playstore\n",
    " Ranked Top 5 in Anveshana\n",
    " Synopsys , Delhi\n",
    " 02/2024\n",
    " • Developed a live IoT project utilizing ESP Cam, Arduino, and machine learning for train accident prevention\n",
    " Implemented obstacle detection and drowsiness detection for the train driver, resulting in winning cash prize and\n",
    " goodies in a competition\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7287239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent,Task,Crew\n",
    "from crewai_tools import ScrapeWebsiteTool,PDFSearchTool,SerperDevTool,FileReadTool\n",
    "\n",
    "\n",
    "resume_tool = FileReadTool(file_path='./template.pdf')\n",
    "\n",
    "\n",
    "researcher_agent = Agent(\n",
    "    role=\"Tech Job Researcher\",\n",
    "    goal=\"Make sure to do amazing analysis on \"\n",
    "        \"job posting to help job applicants land a job for \",\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"As a Job Researcher, your prowess in \"\n",
    "        \"navigating and extracting critical \"\n",
    "        \"information from job postings.\"\n",
    "        \"Your skills help pinpoint the necessary \"\n",
    "        \"qualifications and skills sought \"\n",
    "        \"by employers, forming the foundation for \"\n",
    "        \"effective application tailoring.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "profile_agent = Agent(\n",
    "    role=\"Profile Engineer\",\n",
    "    goal=\"Ensure all necessary details about the user are thoroughly included\",\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"You specialize in verifying and compiling user information from both academic backgrounds \"\n",
    "        \"such as grades, college, school, semesters, degrees or diplomas, and other branches, \"\n",
    "        \"as well as academic status. Additionally, you manage social information such as links, IDs, \"\n",
    "        \"and usernames, handling user data with ease and precision.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Agent 3\n",
    "project_agent = Agent(\n",
    "    role=\"Project Manager\",\n",
    "    goal=\"Ensure to add only relevant projects\",\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"You specialize in managing projects and have a strong understanding of which projects best match the job posting role. \"\n",
    "        \"You can analyze the project's tech stack and filter out the ones that align best with the job requirements. \"\n",
    "        \"You excel at comparing projects and can use various sources to identify the most relevant ones.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Agent 4\n",
    "activity_agent = Agent(\n",
    "    role=\"Extracurricular Activities Coordinator\",\n",
    "    goal=\"Ensure to add only relevant extracurricular activities\",\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"You specialize in managing and curating extracurricular activities, ensuring they align with the user's profile and goals. \"\n",
    "        \"You have a keen eye for identifying activities that best showcase the user's skills and interests, providing a well-rounded view of their capabilities. \"\n",
    "        \"You are adept at analyzing the relevance of various activities and can efficiently filter out those that are most pertinent.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Agent 5\n",
    "work_researcher_agent = Agent(\n",
    "    role=\"Work Experience Coordinator\",\n",
    "    goal=\"Ensure to add only relevant work experiences and prioritize them based on the job role\",\n",
    "    verbose=True,\n",
    "#     tools = [scrape_tool,search_tool],\n",
    "    backstory=(\n",
    "        \"You specialize in handling and organizing work experience, arranging it in an order that highlights the most relevant roles based on the job posting. \"\n",
    "        \"You focus on including experiences that capture the attention of HR, whether they are internships, jobs, freelance projects, or part-time work. \"\n",
    "        \"Your keen understanding of job requirements ensures that only the most pertinent experiences are included and emphasized.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Agent 6\n",
    "format_agent = Agent(\n",
    "    role=\"Resume Formatter\",\n",
    "    goal=\"Ensure the data is structured and formatted in the best resume-friendly manner\",\n",
    "#     tools=[scrape_tool,search_tool],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"You specialize in formatting and structuring resumes to be well-readable by HR and ATS-friendly. \"\n",
    "        \"You excel at highlighting the most relevant points, ensuring the resume is well-structured and formatted. \"\n",
    "        \"Each point is noticeable and well-documented, fitting all essential information onto a single page.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Agent 7\n",
    "latex_format_data_agent = Agent(\n",
    "    role=\"LaTeX Resume Formatter\",\n",
    "    goal=\"Ensure each detail is formatted in LaTeX\",\n",
    "    tools=[resume_tool],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"you dont use the file data only use the format\"\n",
    "        \"You are an expert in LaTeX programming, capable of coding any document format with relevant highlighting and color coding. \"\n",
    "        \"You write optimal LaTeX code to ensure resumes are easily readable by ATS machines. \"\n",
    "        \"follow the formatting syle of the given resume pdf as input \"\n",
    "        \"Your skill ensures that the resume is both visually appealing and technically efficient.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36ceeb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1\n",
    "researcher_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the provided job posting job description ({job_description}) \"\n",
    "        \"to extract key skills, experiences, and qualifications required. \"\n",
    "        \"Utilize available tools to gather content, identify, and categorize the requirements.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A structured list of job requirements, including necessary skills, qualifications, experiences, tech stack, and certifications.\"\n",
    "    ),\n",
    "    agent=researcher_agent,\n",
    "    async_execution=True\n",
    ")\n",
    "\n",
    "#Task 2\n",
    "# Task for Profile Agent: Structure User Data\n",
    "profile_task = Task(\n",
    "    description=(\n",
    "        \"Structure the user's data in Json {academicInfo_json} conver to plain text ensuring that their name, college, and degree are included. \"\n",
    "        \"Review the user data in json {skills_json} convert it to plain text and include essential details, prioritizing the most important information.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        # \"do not add too much details from the link of linkedin and github or anyother if adding the detail can increase the\"\n",
    "        # \"the chance job match then only include it\"\n",
    "        \"The user's details are well-formatted with minimal line spacing. \"\n",
    "        \"Group social links together and place them centrally. \"\n",
    "        \"Organize social links and academic data into sections, using underlines to separate sections. \"\n",
    "        \"link text with color and make important text bold.\"\n",
    "    ),\n",
    "    context=[researcher_task],\n",
    "    agent=profile_agent,\n",
    "    async_execution=True\n",
    ")\n",
    "\n",
    "#Task 3\n",
    "# Task for Project Manager: Sort and Present Projects\n",
    "project_task = Task(\n",
    "    description=(\n",
    "        \"Sort the user's projects which is in Json {projects_json} convert it to plain text and based on their relevance to the job requirements. \"\n",
    "        \"Match each project's tech stack and skills with those required by the job, selecting the 3-5 most relevant projects. \"\n",
    "        \"Exclude any unrelated projects.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A list of the most relevant projects matching the job requirements. \"\n",
    "        \"Structure the project list with improved project names that relate to the job requirements. \"\n",
    "        \"Bold the project names and include the project dates in month/year format. \"\n",
    "        \"Provide a brief description of each project, focusing on the most suitable tech stack related to the job requirements. \"\n",
    "        \"Highlight any live project links with a suitable color if available. \"\n",
    "        \"If space permits, include what the user learned from each project's development.\"\n",
    "    ),\n",
    "    context=[researcher_task],\n",
    "    agent=project_agent,\n",
    "    async_execution=True\n",
    ")\n",
    "\n",
    "\n",
    "#Task 4\n",
    "# Task for Activity Manager: Sort and Present Activities\n",
    "activity_task = Task(\n",
    "    description=(\n",
    "        \"if no activity present skip it\"\n",
    "        \"Format the activity section using bold and italic text to highlight extracurricular activities. \"\n",
    "        \"Include certificates only if they are relevant to the job. \"\n",
    "        \"Sort the activities by their relevance to the job description and remove any unrelated activities. \"\n",
    "        \"Relate your skills to the activities and certificates.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A well-formatted activity section using appropriate bold and italic fonts to highlight achievements. \"\n",
    "        \"Sorted activities and certificates that are most relevant to the job requirements. \"\n",
    "        \"Place the dates aligned to the right of the activity or certificate name. Change the color of any links if present. \"\n",
    "        \"Briefly describe each activity with concise descriptions.\"\n",
    "    ),\n",
    "    context=[researcher_task,profile_task],\n",
    "    agent=activity_agent,\n",
    "    async_execution=True\n",
    ")\n",
    "\n",
    "\n",
    "# Task 5\n",
    "# Task for Work Manager: Structure and Present Work Experience\n",
    "work_task = Task(\n",
    "    description=(\n",
    "        \"This is the most important section. Use the job requirements and qualifications to demonstrate how the user's work experience {workExperience_json}\"\n",
    "        \"can effectively contribute to the job role.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A well-formatted work experience section with color text, listing the user's positions. The previous job roles should be bold with dates in the right corner. \"\n",
    "        \"Mention if the job was remote, hybrid, or on-site. \"\n",
    "        \"Include the company name, prioritizing larger and reputable companies at the top. \"\n",
    "        \"Provide a short explanation of the work experience, relating how the user's previous experience is beneficial for the current role. \"\n",
    "        \"Add skills and projects the user worked on after the short description of the work at the company. \"\n",
    "        \"All details should be clearly mentioned and prioritized based on relevance to the current job and company type.\"\n",
    "    ),\n",
    "    context=[researcher_task],\n",
    "    agent=work_researcher_agent,\n",
    "    async_execution=True\n",
    ")\n",
    "\n",
    "\n",
    "# Task 6\n",
    "format_task = Task(\n",
    "    description=(\n",
    "        \"use previous data to format the user data and bold the section title and use italic font to style color the link text and make sure the whole \"\n",
    "        \"do the formatting in ATS friendly way eary section and date ,link and detilas is easly readable by the ATS machine for resume\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"add horizonatal line in seaction , color the link and heighlight the skills fit the user data in one page only\"\n",
    "        \"use small text to fit in one page only don't use horizonatl margin\"\n",
    "        \"don't use large margin space among the line and esction use less margin and make sure it it is clearnly visible to the HR\"\n",
    "        \"give top left right bottom little margin\"\n",
    "        \"well fomatted document and with each section heighlited \"\n",
    "        \"place the user details , skills ,work experince ,projects ,activity and certification in this order\"\n",
    "        \"but projects ,activity and certification in this order can be changed depends uplon the job requiredment \"\n",
    "        \"the priorty so the aligh the data in most sutaible way\"\n",
    "        \"remove any fake data which is not provided by the user\"\n",
    "        \"\"\n",
    "    ),\n",
    "    context=[researcher_task,profile_task,project_task,activity_task],\n",
    "    agent=format_agent\n",
    ")\n",
    "\n",
    "\n",
    "# LaTeX Task: Convert Data to LaTeX Code\n",
    "latex_task = Task(\n",
    "    description=(\n",
    "        \"Convert each line and link everything into LaTeX code, ensuring each section is appropriately highlighted with bold and suitable colors. \"\n",
    "        \"Do not include page numbers in the code. use small font to and no margin in horizontally\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"do not use the input file data on use the format and the structure of the file to create a latex in that format\"\n",
    "        \"The LaTeX code should cover all user data including user details, projects, work experience, activities, certifications, and everything else. \"\n",
    "        \"It should be well-documented and formatted in the .ltx format, ready for compilation into a LaTeX document.\"\n",
    "    ),\n",
    "    context=[format_task],  # Add more context if needed: research_task, profile_task, project_task, activity_task\n",
    "    output_file = \"new_resume.tex\",\n",
    "    agent=latex_format_data_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ea07e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = {'job_description': 'About the job\\nWe are looking for a Machine Learning Engineers committed to developing AI/ML methods in accelerating the discovery of novel functional materials, Reaction Language Models, and drug molecules. You will work closely with domain experts and academic advisors.\\n\\n\\nYou will be a member of a multi-disciplinary team working in a fast-paced startup environment. If you are motivated on building revolutionary technologies and enjoy working on ambitious projects QpiVolta is the right place for you.\\nQualifications and Experience\\nBackground in Computer science, Physics, Chemistry, Mathematics, Statistics or a related field of knowledge\\nDevelop tools and workflows that can be integrated into commercial software products\\nWork with customers on various machine learning-centric Materials Science research projects\\nProficiency in Software development, collaborative development and python\\nExperience with version control, unit and functional testing, containerisation and orchestration.\\nIn-depth understanding and hands-on experience in deep learning algorithms domains such as Graph Neural Networks, Transformers, Generative Models\\nExperience with Monte-Carlo tree search, genetic algorithms, and reinforcement learning, and experience with probabilistic models is a plus (e.g., Gaussian Processes, Bayesian Neural Networks)\\nProficiency with deep learning frameworks (PyTorch is preferable, TensorFlow, JAX)\\nBasic knowledge of material science, molecular properties and/or chemical reactions cheminformatics and related libraries (e.g., RDKit, PyMAtgen)is a plus\\nExcellent oral and written communication, presentation, and analytical skills', \n",
    "        'personal_details_json': {'name': 'Rohit Kumar', 'email': 'rohitcode005@gmail.com', 'linkedin': 'https://www.linkedin.com/in/rohit-kumar-66522518a/', 'github': 'https://github.com/Rohitw3code', 'kaggle': 'https://www.kaggle.com/rohitcode123/', 'leetcode': ''}, \n",
    "        'academicInfo_json': {'collegeName': 'Sarala Birla University', 'startYear': '2024-06-12', 'endYear': '2024-06-19', 'cgpa': '7.56', 'degree': 'B.Tech AI'},\n",
    "        'skills_json': {'programmingLanguages': 'python,c,java,javascript', 'otherSkills': 'problem solving,communication'}, \n",
    "        'workExperience_json': [{'position': 'Data Engineer', 'company': 'Taiyo.ai', 'workDesc': ' Web Scraping : Developed Python script using OOP principles to scrape data from World Bank and IADB  government websites. Implemented translation of websites into English for uniformity.  • Data Pipeline: Established a robust data pipeline integrated with Google Cloud for seamless data transfer. Utilized  Docker to containerize the scraping and preprocessing processes for portability and scalability.  • Data Preprocessing : Employed PySpark on Databricks along with Pandas and NumPy for efficient data  preprocessing. Utilized visualization libraries like Matplotlib and Seaborn for exploratory data analysis.  • End-to-End Pipeline : Developed an end-to-end ETL pipeline for streamlined data extraction, transformation, and  loading.', 'jobType': 'remote', 'wdate': '2024-06-12'}, {'position': 'Prompt Engineer', 'company': 'Scale AI', 'workDesc': ' Enhanced prompt-based AI model : Reviewed and optimized a language model (LLM) for generating code in  data science and machine learning tasks  • Code review : Examined code generated by the LLM model, ensuring accuracy, efficiency, and adherence to best  practices in Python and other programming languages', 'jobType': 'remote', 'wdate': '2024-06-12'}], \n",
    "        'projects_json': [{'projectName': 'AI ResumeRover (LLM langchain)', 'projectDesc': ' Functionality: A platform for HR to upload and manage hundreds  of resumes simultaneously. Enabled HR to filter resumes efficiently based on project needs and employee.  ', 'techStack': 'Langchain and fine-tuned with OpenAI and FAISS , Python , Streamlit', 'pdate': '2024-06-26','github': 'www.github/rohitw3code', 'liveLink': ''}, {'projectName': 'Data Science QuickFlow',\n",
    "        'projectDesc': ' Developed a web tool for a data scientist using Flask,React,Tailwind  CSS,Pandas,and NumPy.This platform enables data scientists to perform all data preprocessing task,feature  selection, and machine learning model training tasks without writing code. It supports 17 regression and 20  classification algorithms and code generation', 'techStack': ' reactjs,Flask api,pandas,numpy,sklearn,javascript', 'pdate': '2023-11-02', 'liveLink': '', 'github': ''}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6148f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df7278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_application_crew = Crew(\n",
    "    agents=[researcher_agent,profile_agent,\n",
    "            project_agent,activity_agent,\n",
    "            work_researcher_agent,format_agent,latex_format_data_agent],\n",
    "\n",
    "    tasks=[researcher_task,profile_task,\n",
    "          project_task,activity_task,\n",
    "          work_task,format_task,latex_task],\n",
    "    verbose=True,\n",
    "    memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ab602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = job_application_crew.kickoff(inputs=input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246fa83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\\documentclass{article}\n",
       "\\usepackage{xcolor}\n",
       "\\usepackage{enumitem}\n",
       "\n",
       "\\definecolor{heading}{RGB}{0,0,128}\n",
       "\\definecolor{subheading}{RGB}{0,128,0}\n",
       "\\definecolor{skills}{RGB}{128,0,0}\n",
       "\n",
       "\\begin{document}\n",
       "\n",
       "{\\color{heading}\\textbf{\\Huge Sarala Birla University}} \\\\\n",
       "B.Tech AI \\\\\n",
       "June 12, 2024 - June 19, 2024 \\\\\n",
       "CGPA: 7.56\n",
       "\n",
       "{\\color{subheading}\\textbf{Social Information:}}\n",
       "\n",
       "{\\color{skills}\\textbf{Programming Languages:}} Python, C, Java, JavaScript\n",
       "\n",
       "---\n",
       "\n",
       "{\\color{subheading}\\textbf{Academic Details:}}\n",
       "\n",
       "{\\color{skills}\\textbf{Education}}\n",
       "\\begin{itemize}[label={-}]\n",
       "    \\item {\\color{skills}\\textbf{Bachelor of Technology in Artificial Intelligence}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Sarala Birla University\n",
       "        \\item June 12, 2024 - June 19, 2024\n",
       "        \\item CGPA: 7.56\n",
       "    \\end{itemize}\n",
       "\\end{itemize}\n",
       "\n",
       "---\n",
       "\n",
       "{\\color{subheading}\\textbf{Skills:}}\n",
       "\\begin{enumerate}\n",
       "    \\item {\\color{skills}\\textbf{Programming Languages:}} Python, C, Java, JavaScript\n",
       "    \\item {\\color{skills}\\textbf{AI Skills:}} Tensorflow, PyTorch, Sklearn, Pandas, NumPy, Matplotlib\n",
       "    \\item {\\color{skills}\\textbf{Machine Learning Tools:}} HuggingFace, Langchain, OpenCV, LLM, NLP\n",
       "    \\item {\\color{skills}\\textbf{Web Development:}} Flask, React, nodejs\n",
       "    \\item {\\color{skills}\\textbf{Database:}} SQL, NoSQL\n",
       "    \\item {\\color{skills}\\textbf{Version Control:}} Git\n",
       "    \\item {\\color{skills}\\textbf{Other Tools:}} Linux, Docker, Firebase, MongoDB\n",
       "    \\item {\\color{skills}\\textbf{Specialties:}} Machine Learning, Deep Learning, Artificial Intelligence, Neural Networks\n",
       "\\end{enumerate}\n",
       "\n",
       "---\n",
       "\n",
       "{\\color{subheading}\\textbf{Work Experience:}}\n",
       "\\begin{enumerate}\n",
       "    \\item {\\color{skills}\\textbf{Data Engineer}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Taiyo.ai\n",
       "        \\item Web scraping, Python scripting, data preprocessing, analysis using Pandas, NumPy, Matplotlib, Seaborn\n",
       "    \\end{itemize}\n",
       "    \n",
       "    \\item {\\color{skills}\\textbf{Prompt Engineer}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Scale AI\n",
       "        \\item Reviewing LLM model code generation, improving prompt generative AI models\n",
       "    \\end{itemize}\n",
       "\\end{enumerate}\n",
       "\n",
       "---\n",
       "\n",
       "{\\color{subheading}\\textbf{Projects:}}\n",
       "\\begin{enumerate}\n",
       "    \\item {\\color{skills}\\textbf{AI ResumeRover (LLM langchain)}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item A platform for HR to upload and manage resumes efficiently, utilizing Langchain, OpenAI, FAISS, Python, and Streamlit.\n",
       "    \\end{itemize}\n",
       "    \n",
       "    \\item {\\color{skills}\\textbf{Data Science QuickFlow}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item A web tool for data scientists using Flask, React, Tailwind CSS, Pandas, and NumPy, supporting data preprocessing, feature selection, and machine learning tasks\n",
       "    \\end{itemize}\n",
       "\\end{enumerate}\n",
       "\n",
       "---\n",
       "\n",
       "{\\color{subheading}\\textbf{Certifications:}}\n",
       "\\begin{itemize}[label={-}]\n",
       "    \\item Any relevant certifications in machine learning, deep learning, or artificial intelligence would be beneficial\n",
       "\\end{itemize}\n",
       "\n",
       "---\n",
       "\n",
       "{\\color{subheading}\\textbf{Extracurricular Activities:}}\n",
       "\\begin{enumerate}\n",
       "    \\item {\\color{skills}\\textbf{Machine Learning Project Showcase}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Developed and implemented a machine learning project that achieved a 95% accuracy rate in predicting customer churn for a simulated telecommunications company.\n",
       "    \\end{itemize}\n",
       "    \n",
       "    \\item {\\color{skills}\\textbf{Artificial Intelligence Research}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Conducted independent research on the applications of artificial intelligence in natural language processing, resulting in a published paper in the International Journal of AI Research.\n",
       "    \\end{itemize}\n",
       "    \n",
       "    \\item {\\color{skills}\\textbf{Online Course Completion}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Completed the \"Machine Learning A-Z™: Hands-On Python & R In Data Science\" online course by Udemy, covering advanced machine learning techniques and algorithms.\n",
       "    \\end{itemize}\n",
       "    \n",
       "    \\item {\\color{skills}\\textbf{Data Science Hackathon Winner}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Secured first place in a regional data science hackathon by developing a machine learning model that optimized supply chain logistics for a leading e-commerce company.\n",
       "    \\end{itemize}\n",
       "    \n",
       "    \\item {\\color{skills}\\textbf{Deep Learning Workshop}}\n",
       "    \\begin{itemize}[label={-}]\n",
       "        \\item Participated in a hands-on workshop on deep learning techniques, including neural network design and training, organized by the AI Society at the university.\n",
       "    \\end{itemize}\n",
       "\\end{enumerate}\n",
       "\n",
       "\\end{document}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da940f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4804fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2defd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45246585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792dbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e833ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d5098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ed7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867dd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b897ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc06eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2bec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750fd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4331112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
